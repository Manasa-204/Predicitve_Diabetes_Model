{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üî• ENHANCED HYBRID DIABETES PREDICTION PIPELINE\n",
    "# Includes Feature Importance + Dynamic User Input\n",
    "# =====================================================\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# -----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib # Added import for joblib\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# -----------------------------------------\n",
    "df = pd.read_csv(r\"/content/diabetes_prediction_dataset.csv\")\n",
    "\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3Ô∏è‚É£ Encode Categorical Columns\n",
    "# -----------------------------------------\n",
    "cat_cols = ['gender', 'smoking_history']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4Ô∏è‚É£ Define Features & Target\n",
    "# -----------------------------------------\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5Ô∏è‚É£ Split into Train-Test\n",
    "# -----------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6Ô∏è‚É£ Handle Class Imbalance (SMOTETomek)\n",
    "# -----------------------------------------\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_res, y_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After balancing:\")\n",
    "print(\"Training data size:\", X_res.shape)\n",
    "print(\"Class distribution:\\n\", y_res.value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7Ô∏è‚É£ Scale Numeric Columns\n",
    "# -----------------------------------------\n",
    "scaler = RobustScaler()\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8Ô∏è‚É£ Prepare SVM training sample (10% for speed)\n",
    "# -----------------------------------------\n",
    "X_svm_train, _, y_svm_train, _ = train_test_split(\n",
    "    X_res_scaled, y_res, train_size=0.1, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"SVM training on sample size: {X_svm_train.shape[0]}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9Ô∏è‚É£ Define Individual Models\n",
    "# -----------------------------------------\n",
    "models = {\n",
    "    \"SVM\": SVC(probability=False, kernel='rbf', random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# üîü Train Individual Models\n",
    "# -----------------------------------------\n",
    "results = {}\n",
    "\n",
    "# Train SVM on sample only\n",
    "print(\"\\n=== Training SVM ===\")\n",
    "models[\"SVM\"].fit(X_svm_train, y_svm_train)\n",
    "print(\"SVM training completed.\")\n",
    "\n",
    "# Train others on full balanced set\n",
    "print(\"\\n=== Training Neural Network ===\")\n",
    "models[\"Neural Network\"].fit(X_res_scaled, y_res)\n",
    "print(\"Neural Network training completed.\")\n",
    "\n",
    "print(\"\\n=== Training XGBoost ===\")\n",
    "models[\"XGBoost\"].fit(X_res_scaled, y_res)\n",
    "print(\"XGBoost training completed.\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Evaluate Individual Models\n",
    "# -----------------------------------------\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Evaluating {name} ===\")\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\"Accuracy\": acc}\n",
    "\n",
    "    print(\"Accuracy:\", round(acc*100, 2), \"%\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Create and Train Hybrid Ensemble (hard voting)\n",
    "# -----------------------------------------\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('svm', models['SVM']),\n",
    "                ('nn', models['Neural Network']),\n",
    "                ('xgb', models['XGBoost'])],\n",
    "    voting='hard'  # use hard voting since svm has no predict_proba\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training Hybrid Ensemble Model ===\")\n",
    "def manual_ensemble_predict(X):\n",
    "    preds = []\n",
    "    preds.append(models['SVM'].predict(X))\n",
    "    preds.append(models['Neural Network'].predict(X))\n",
    "    preds.append(models['XGBoost'].predict(X))\n",
    "\n",
    "    preds = np.array(preds)  # shape (3, n_samples)\n",
    "\n",
    "    from scipy.stats import mode\n",
    "    majority_preds, _ = mode(preds, axis=0)\n",
    "    return majority_preds.flatten()\n",
    "\n",
    "print(\"Hybrid ensemble training completed.\")\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Evaluate Hybrid Ensemble\n",
    "# -----------------------------------------\n",
    "\n",
    "print(\"\\n=== Evaluating Manual Hybrid Ensemble ===\")\n",
    "y_pred_ensemble = manual_ensemble_predict(X_test_scaled)\n",
    "\n",
    "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"Hybrid Ensemble Accuracy: {round(acc_ensemble*100, 2)}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "cm_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "sns.heatmap(cm_ensemble, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - Hybrid Ensemble\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "results['Hybrid Ensemble'] = {\"Accuracy\": acc_ensemble}\n",
    "\n",
    "joblib.dump(models[\"XGBoost\"], \"diabetes_xgb_model.pkl\") # Changed xgb_model to models[\"XGBoost\"]\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nüéØ Pickle files created successfully!\")\n",
    "print(\"Saved as: diabetes_xgb_model.pkl and scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (100000, 9)\n",
      "Columns: ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']\n",
      "Missing values per column:\n",
      " gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n",
      "After balancing:\n",
      "Training data size: (145750, 8)\n",
      "Class distribution:\n",
      " 1    72875\n",
      "0    72875\n",
      "Name: diabetes, dtype: int64\n",
      "SVM training on sample size: 14575\n",
      "\n",
      "=== Training SVM ===\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# üî• ENHANCED HYBRID DIABETES PREDICTION PIPELINE\n",
    "# Includes Feature Importance + Dynamic User Input\n",
    "# =====================================================\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# -----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib # Added import for joblib\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# -----------------------------------------\n",
    "df = pd.read_csv(r\"D:\\Manasa College\\SE\\venv\\data\\diabetes_prediction_dataset.csv\")\n",
    "\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3Ô∏è‚É£ Encode Categorical Columns\n",
    "# -----------------------------------------\n",
    "cat_cols = ['gender', 'smoking_history']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4Ô∏è‚É£ Define Features & Target\n",
    "# -----------------------------------------\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5Ô∏è‚É£ Split into Train-Test\n",
    "# -----------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6Ô∏è‚É£ Handle Class Imbalance (SMOTETomek)\n",
    "# -----------------------------------------\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_res, y_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After balancing:\")\n",
    "print(\"Training data size:\", X_res.shape)\n",
    "print(\"Class distribution:\\n\", y_res.value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7Ô∏è‚É£ Scale Numeric Columns\n",
    "# -----------------------------------------\n",
    "scaler = RobustScaler()\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8Ô∏è‚É£ Prepare SVM training sample (10% for speed)\n",
    "# -----------------------------------------\n",
    "X_svm_train, _, y_svm_train, _ = train_test_split(\n",
    "    X_res_scaled, y_res, train_size=0.1, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"SVM training on sample size: {X_svm_train.shape[0]}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9Ô∏è‚É£ Define Individual Models\n",
    "# -----------------------------------------\n",
    "models = {\n",
    "    \"SVM\": SVC(probability=False, kernel='rbf', random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# üîü Train Individual Models\n",
    "# -----------------------------------------\n",
    "results = {}\n",
    "\n",
    "# Train SVM on sample only\n",
    "print(\"\\n=== Training SVM ===\")\n",
    "models[\"SVM\"].fit(X_svm_train, y_svm_train)\n",
    "print(\"SVM training completed.\")\n",
    "\n",
    "# Train others on full balanced set\n",
    "print(\"\\n=== Training Neural Network ===\")\n",
    "models[\"Neural Network\"].fit(X_res_scaled, y_res)\n",
    "print(\"Neural Network training completed.\")\n",
    "\n",
    "print(\"\\n=== Training XGBoost ===\")\n",
    "models[\"XGBoost\"].fit(X_res_scaled, y_res)\n",
    "print(\"XGBoost training completed.\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Evaluate Individual Models\n",
    "# -----------------------------------------\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Evaluating {name} ===\")\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\"Accuracy\": acc}\n",
    "\n",
    "    print(\"Accuracy:\", round(acc*100, 2), \"%\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Create and Train Hybrid Ensemble (hard voting)\n",
    "# -----------------------------------------\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('svm', models['SVM']),\n",
    "                ('nn', models['Neural Network']),\n",
    "                ('xgb', models['XGBoost'])],\n",
    "    voting='hard'  # use hard voting since svm has no predict_proba\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training Hybrid Ensemble Model ===\")\n",
    "def manual_ensemble_predict(X):\n",
    "    preds = []\n",
    "    preds.append(models['SVM'].predict(X))\n",
    "    preds.append(models['Neural Network'].predict(X))\n",
    "    preds.append(models['XGBoost'].predict(X))\n",
    "\n",
    "    preds = np.array(preds)  # shape (3, n_samples)\n",
    "\n",
    "    from scipy.stats import mode\n",
    "    majority_preds, _ = mode(preds, axis=0)\n",
    "    return majority_preds.flatten()\n",
    "\n",
    "print(\"Hybrid ensemble training completed.\")\n",
    "# -----------------------------------------\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Evaluate Hybrid Ensemble\n",
    "# -----------------------------------------\n",
    "\n",
    "print(\"\\n=== Evaluating Manual Hybrid Ensemble ===\")\n",
    "y_pred_ensemble = manual_ensemble_predict(X_test_scaled)\n",
    "\n",
    "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"Hybrid Ensemble Accuracy: {round(acc_ensemble*100, 2)}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "cm_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "sns.heatmap(cm_ensemble, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - Hybrid Ensemble\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "results['Hybrid Ensemble'] = {\"Accuracy\": acc_ensemble}\n",
    "\n",
    "joblib.dump(models[\"XGBoost\"], \"diabetes_xgb_model.pkl\") # Changed xgb_model to models[\"XGBoost\"]\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nüéØ Pickle files created successfully!\")\n",
    "print(\"Saved as: diabetes_xgb_model.pkl and scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
